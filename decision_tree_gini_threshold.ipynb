{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.14178776741028 seconds\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import ast\n",
    "import pysam \n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import time \n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "from tabulate import tabulate\n",
    "import csv\n",
    "import random\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "min_quality_score = 8\n",
    "\n",
    "\n",
    "\n",
    "assembly_ = open(\"/private/groups/migalab/dan/reference/hg002v1.0.1.fasta\", \"r\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#Load the reference genome and make it into a dictionary \n",
    "fasta_sequences = SeqIO.parse(assembly_, \"fasta\")\n",
    "assembly={}\n",
    "for fasta in fasta_sequences:\n",
    "    name, sequence = fasta.id, str(fasta.seq)\n",
    "    assembly[name] = sequence\n",
    "\n",
    "#Make a dictionary for all the chromosomes and their corresponding sequence length \n",
    "assembly_sequence_length = {}    \n",
    "for chromosome in assembly:\n",
    "    assembly_sequence_length[chromosome] = len(assembly[chromosome])\n",
    "    \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print (elapsed_time, \"seconds\")\n",
    "assembly_.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CDR_regions = '/private/groups/migalab/dan/data_analysis/young_old_analysis/HG002_DiMeLo_CENPA_youngpassage.hmmCDR_only_CDR_Dan_certified.bed'\n",
    "output_dir = Path('/private/groups/migalab/dan/data_analysis/HG002_figure2/b_revised_multi_region')\n",
    "CENPA_AS_bam_file = '/private/groups/migalab/dan/06_11_24_R1041_UL_DiMeLo_CENPAyoung_1/20240611_1126_1H_PAW33460_814408d8/pod5/06_11_24_R1041_UL_DiMeLo_CENPAyoung_1_5mA_6mC_winnowmap_MD.bam'\n",
    "CENPC_AS_bam_file = '/private/groups/migalab/dan/01_09_24_R1041_DiMeLoAdaptive_CENPC/01_09_24_R1041_DiMeLoAdaptive_CENPC/01_09_24_R1041_DiMeLoAdaptive_CENPC/20240109_1200_6B_PAS52674_0adbae11/pod5_pass/explicit/01_09_24_R1041_DiMeLoAdaptive_CENPC_5mC_6mA_winnowmap_sorted_MD.bam'\n",
    "H3K9me3_AS_bam_file = '/private/groups/migalab/dan/08_05_24_R1041_ULadapt_Dimelo_H3K9ME3/08_05_24_R1041_ULadapt_Dimelo_H3K4ME3/08_05_24_R1041_ULadapt_Dimelo_H3K4ME3_1/20240805_1148_1F_PAU87705_0451cc00/pod5/08_05_24_R1041_ULadapt_Dimelo_H3K4ME3_mA_mC_winnowmap_sorted_MD.bam'\n",
    "ref_genome_file = Path('/private/groups/migalab/dan/reference/hg002v1.0.1.fasta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' here in the code, I am formulating the CDR regions and listing the CDRs in each and every chromosome'''\n",
    "input_file = '/private/groups/migalab/dan/data_analysis/young_old_analysis/HG002_DiMeLo_CENPA_youngpassage.hmmCDR_only_CDR_Dan_certified.bed'\n",
    "CDR_dict = {}\n",
    "with open(input_file, 'r') as infile:  \n",
    "    for i in infile:\n",
    "        chr_num = i.split('\\t')[0]\n",
    "        CDR_start = i.split('\\t')[1]\n",
    "        CDR_end = i.split('\\t')[2].split('\\n')[0]\n",
    "        if chr_num not in CDR_dict:\n",
    "            CDR_dict[chr_num] = [[CDR_start ,CDR_end]]\n",
    "        elif chr_num in CDR_dict:  \n",
    "            CDR_dict[chr_num].append ([CDR_start ,CDR_end])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Based on the CDR regions, I am obtaining CDR adjacent regions in the same format as the CDR data set above'''\n",
    "CDR_adjacent = {}\n",
    "for chromosome in CDR_dict: \n",
    "    CDR_adjacent[chromosome] =[]\n",
    "    for CDR in CDR_dict[chromosome]: \n",
    "        #print (CDR) \n",
    "        CDR_adjacent_left_space = [int(CDR[0]) - 1001, int(CDR[0]) - 1]\n",
    "        CDR_adjacent_right_space = [int(CDR[1]) + 1, int(CDR[1]) + 1001]\n",
    "        \n",
    "        CDR_adjacent[chromosome].append (CDR_adjacent_left_space)\n",
    "        CDR_adjacent[chromosome].append (CDR_adjacent_right_space)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The purpose of the code here is to make an active array where the chromosome name is\n",
    "the dictionary key. The active array blocks are in lists inside the key.\n",
    "'''\n",
    "import os\n",
    "input_file = '/private/groups/migalab/dan/data_analysis/alpha_bed/hg002v1.0.fasta.manualAlpha.cenSat_H1L_merged.bed'\n",
    "active_dict = {}\n",
    "with open(input_file, 'r') as infile:  \n",
    "    num = 0 \n",
    "    previous_chr_num = \"\"\n",
    "    previous_parental_status = \"\"\n",
    "    for i in infile:\n",
    "        chr_num = i.split ('_')[0]\n",
    "        parental_status = i.split ('_')[1][0:8]\n",
    "        if chr_num == previous_chr_num and parental_status !=previous_parental_status:\n",
    "            num = 0 \n",
    "        elif chr_num == previous_chr_num and parental_status ==previous_parental_status:\n",
    "            pass \n",
    "        else: \n",
    "            num = 0 \n",
    "        active = i.split ()\n",
    "        if active[0] not in active_dict:\n",
    "            \n",
    "            active_dict[active[0]] = [[int(active[1]) ,int(active[2])]]\n",
    "        else:\n",
    "            active_dict[active[0]].append([int(active[1]) ,int(active[2])])\n",
    "        previous_chr_num = chr_num \n",
    "        previous_parental_status = parental_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "none_CDR_active = {}\n",
    "for chromosome in CDR_dict: \n",
    "    none_CDR_active[chromosome] = [] \n",
    "    active_start = active_dict[chromosome][0][0]\n",
    "    active_end = active_dict[chromosome][0][1]\n",
    "    CDR_start_position = int (CDR_dict[chromosome][0][0]) - 1 \n",
    "    CDR_end_position = int (CDR_dict[chromosome][-1][1]) + 1\n",
    "    none_CDR_active[chromosome].append ([active_start, CDR_start_position])\n",
    "    for coordinate in range(len(CDR_dict[chromosome]) - 1):\n",
    "        # Generate in-between coordinates\n",
    "        \n",
    "        start_of_next = int (CDR_dict[chromosome][coordinate + 1][0]) - 1 \n",
    "        end_of_current = int (CDR_dict[chromosome][coordinate][1]) + 1 \n",
    "        # Ensure there's no overlap and the next start is greater than the current end\n",
    "        if int(start_of_next) > int(end_of_current):\n",
    "            none_CDR_active[chromosome].append([end_of_current, start_of_next])\n",
    "    \n",
    "none_CDR_active[ chromosome].append ([CDR_end_position, active_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_regions(chromosome_dict):\n",
    "    \"\"\"\n",
    "    Counts the number of regions (small lists) for each chromosome in the dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "        chromosome_dict (dict): Dictionary where keys are chromosome names and values are lists of regions.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with chromosome names as keys and the count of regions as values.\n",
    "    \"\"\"\n",
    "    region_counts = {}\n",
    "    for chromosome, regions in chromosome_dict.items():\n",
    "        region_counts[chromosome] = len(regions)\n",
    "    return region_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chr10_MATERNAL': 15, 'chr10_PATERNAL': 13, 'chr11_MATERNAL': 20, 'chr11_PATERNAL': 19, 'chr12_MATERNAL': 17, 'chr12_PATERNAL': 16, 'chr13_MATERNAL': 15, 'chr13_PATERNAL': 12, 'chr14_MATERNAL': 16, 'chr14_PATERNAL': 17, 'chr15_MATERNAL': 14, 'chr15_PATERNAL': 14, 'chr16_MATERNAL': 13, 'chr16_PATERNAL': 18, 'chr17_MATERNAL': 16, 'chr17_PATERNAL': 19, 'chr18_MATERNAL': 13, 'chr18_PATERNAL': 13, 'chr19_MATERNAL': 17, 'chr19_PATERNAL': 18, 'chr1_MATERNAL': 12, 'chr1_PATERNAL': 11, 'chr20_MATERNAL': 13, 'chr20_PATERNAL': 15, 'chr21_MATERNAL': 13, 'chr21_PATERNAL': 13, 'chr22_MATERNAL': 10, 'chr22_PATERNAL': 15, 'chr2_MATERNAL': 15, 'chr2_PATERNAL': 20, 'chr3_MATERNAL': 17, 'chr3_PATERNAL': 15, 'chr4_MATERNAL': 11, 'chr4_PATERNAL': 14, 'chr5_MATERNAL': 16, 'chr5_PATERNAL': 15, 'chr6_MATERNAL': 18, 'chr6_PATERNAL': 12, 'chr7_MATERNAL': 16, 'chr7_PATERNAL': 15, 'chr8_MATERNAL': 16, 'chr8_PATERNAL': 15, 'chr9_MATERNAL': 13, 'chr9_PATERNAL': 14, 'chrX_MATERNAL': 15}\n",
      "{'chr10_MATERNAL': 15, 'chr10_PATERNAL': 15, 'chr11_MATERNAL': 15, 'chr11_PATERNAL': 15, 'chr12_MATERNAL': 15, 'chr12_PATERNAL': 15, 'chr13_MATERNAL': 15, 'chr13_PATERNAL': 14, 'chr14_MATERNAL': 15, 'chr14_PATERNAL': 15, 'chr15_MATERNAL': 15, 'chr15_PATERNAL': 11, 'chr16_MATERNAL': 15, 'chr16_PATERNAL': 14, 'chr17_MATERNAL': 15, 'chr17_PATERNAL': 15, 'chr18_MATERNAL': 15, 'chr18_PATERNAL': 15, 'chr19_MATERNAL': 15, 'chr19_PATERNAL': 15, 'chr1_MATERNAL': 15, 'chr1_PATERNAL': 15, 'chr20_MATERNAL': 15, 'chr20_PATERNAL': 15, 'chr21_MATERNAL': 15, 'chr21_PATERNAL': 15, 'chr22_MATERNAL': 15, 'chr22_PATERNAL': 15, 'chr2_MATERNAL': 15, 'chr2_PATERNAL': 15, 'chr3_MATERNAL': 15, 'chr3_PATERNAL': 15, 'chr4_MATERNAL': 15, 'chr4_PATERNAL': 15, 'chr5_MATERNAL': 15, 'chr5_PATERNAL': 15, 'chr6_MATERNAL': 15, 'chr6_PATERNAL': 15, 'chr7_MATERNAL': 15, 'chr7_PATERNAL': 15, 'chr8_MATERNAL': 15, 'chr8_PATERNAL': 15, 'chr9_MATERNAL': 15, 'chr9_PATERNAL': 15, 'chrX_MATERNAL': 15}\n"
     ]
    }
   ],
   "source": [
    "def split_into_segments(chromosome_dict, segment_size=5000):\n",
    "    \"\"\"\n",
    "    Splits the ranges in the chromosome dictionary into smaller segments of a specified size.\n",
    "    Ignores segments smaller than the specified size.\n",
    "    \n",
    "    Parameters:\n",
    "        chromosome_dict (dict): Dictionary with chromosome keys and list of ranges.\n",
    "        segment_size (int): Size of each segment to create (default: 5000).\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with the same keys but ranges split into smaller segments.\n",
    "    \"\"\"\n",
    "    segmented_dict = {}\n",
    "\n",
    "    for chromosome, ranges in chromosome_dict.items():\n",
    "        segmented_ranges = []\n",
    "        for start_str, end_str in ranges:\n",
    "            #print (start_str, end_str)\n",
    "            start = int(start_str)\n",
    "            end = int(end_str)\n",
    "            # Generate segments\n",
    "            while start + segment_size - 1 < end:  # Only create segments of full size\n",
    "                segment_end = start + segment_size - 1\n",
    "                segmented_ranges.append([str(start), str(segment_end)])\n",
    "                start += segment_size  # Move to the next segment\n",
    "        segmented_dict[chromosome] = segmented_ranges\n",
    "\n",
    "    return segmented_dict\n",
    "\n",
    "\n",
    "\n",
    "# Call the function\n",
    "segmented_chromosome_CDR_dict = split_into_segments(CDR_dict)\n",
    "segmented_chromosome_non_CDR_dict = split_into_segments(none_CDR_active)\n",
    "\n",
    "print (count_regions(segmented_chromosome_CDR_dict))\n",
    "\n",
    "\n",
    "def preserve_first_x_regions(chromosome_dict, x):\n",
    "    \"\"\"\n",
    "    Preserves only the first x small lists (regions) for each chromosome in the dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "        chromosome_dict (dict): Dictionary with chromosome names as keys and lists of regions as values.\n",
    "        x (int): The number of regions to preserve for each chromosome.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with only the first x regions for each chromosome.\n",
    "    \"\"\"\n",
    "    limited_dict = {}\n",
    "    for chromosome, regions in chromosome_dict.items():\n",
    "        limited_dict[chromosome] = regions[:x]  # Preserve only the first x regions\n",
    "    return limited_dict\n",
    "\n",
    "trimmed_segmented_chromosome_non_CDR_dict = preserve_first_x_regions(segmented_chromosome_non_CDR_dict, 15)\n",
    "print (count_regions(trimmed_segmented_chromosome_non_CDR_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The idea of this function is to isolate the the desired regions (here in the function, it is called the subset) in the mod \n",
    "numpy array without dashes(insertions)'''\n",
    "\n",
    "def mod_subset_producing_step (mod_no_dash,alignment_dash,target_start_no_dash,target_end_no_dash):\n",
    "    #mod_no_dash = is the numpy array of the mod without any insertions and deletions\n",
    "    # alignment_dash = is the alignment sequence with the dashes in it \n",
    "    # target_start = it's the subset starting position WITHOUT the dashes!!! \n",
    "\n",
    "\n",
    "    # Create a mask to identify non-dash positions\n",
    "    mask = [char != '-' for char in alignment_dash]\n",
    "\n",
    "    # Generate cumulative counts only for True values in the mask\n",
    "    cumulative_counts = list(itertools.accumulate(mask))\n",
    "\n",
    "\n",
    "    \n",
    "    # Create the final indexes list\n",
    "    indexes = [count - 1 if is_non_dash else '-' for count, is_non_dash in zip(cumulative_counts, mask)]\n",
    "\n",
    "\n",
    "\n",
    "    target_start_dash = indexes.index (target_start_no_dash)\n",
    "\n",
    "        \n",
    "    try:\n",
    "        target_end_dash = indexes.index (target_end_no_dash)\n",
    "    except ValueError: \n",
    "        target_end_dash = indexes[-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #obtain dashed alignment \n",
    "    alignment_dash_sequence_pre_subset = alignment_dash[0:target_start_dash]\n",
    "    alignment_dash_sequence_subset = alignment_dash[target_start_dash:target_end_dash]\n",
    "\n",
    "    #create no dash alignment \n",
    "    alignment_no_dash_sequence_pre_subset = alignment_dash_sequence_pre_subset.replace(\"-\",\"\")\n",
    "    alignment_no_dash_sequence_subset = alignment_dash_sequence_subset.replace(\"-\",\"\")\n",
    "\n",
    "    subset_no_dash_start = len(alignment_no_dash_sequence_pre_subset)\n",
    "    subset_no_dash_end = subset_no_dash_start + len(alignment_no_dash_sequence_subset)\n",
    "\n",
    "    #make mod_no_dash alignment\n",
    "    mod_subset = mod_no_dash[subset_no_dash_start:subset_no_dash_end]\n",
    "\n",
    "    return mod_subset\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "The input of the function is a dictionary in the format of 'chromosome':[[start,end],[start,end]] \n",
    "'''\n",
    "def region_read_mA_density_calculator (chromosome_coordinates,threshold,mod_tag,filtering_val): \n",
    "    read_region_check = {}\n",
    "    read_CDR_region_distribution = {}\n",
    "\n",
    "\n",
    "    #get each chromosome\n",
    "    for chr_name in chromosome_coordinates:\n",
    "\n",
    "        for region in chromosome_coordinates[chr_name]:\n",
    "            region_base = 0 \n",
    "\n",
    "            region_start_index = int(region[0])\n",
    "            region_end_index = int(region[1])\n",
    "\n",
    "            \n",
    "            for read in bamfile.fetch(chr_name,region_start_index,region_end_index):\n",
    "                chromosome = bamfile.get_reference_name(read.reference_id)\n",
    "                read_name = read.query_name \n",
    "                read_start_position = read.reference_start\n",
    "                read_end_position = read.reference_end\n",
    "                \n",
    "                    \n",
    "                \n",
    "                #make an if statement to check a specific read front, middle, end regions \n",
    "                #setting read start, end, density, length variables \n",
    "                    \n",
    "\n",
    "                #Get the starting and ending positions of the reads \n",
    "                \n",
    "                read_density = 0 \n",
    "\n",
    "                \n",
    "                #Get sequence information which shows deletions and insertions \n",
    "                sequence = read.get_aligned_pairs(matches_only=False, with_seq = True)\n",
    "\n",
    "\n",
    "                #make |a numpy of the sequence length which eliminates the deletion\n",
    "                read_sequence_insertion_included = ''\n",
    "                genomic_alignment_sequence_deletion_mistach_included = ''\n",
    "                \n",
    "                for item in sequence:\n",
    "                    if item[0] is None:\n",
    "                        read_sequence_insertion_included+='-'\n",
    "                    elif item[1] is None:\n",
    "                        genomic_alignment_sequence_deletion_mistach_included += '-'\n",
    "                    else: \n",
    "                        read_sequence_insertion_included+=item[2]\n",
    "                        genomic_alignment_sequence_deletion_mistach_included +=item[2]\n",
    "\n",
    "                \n",
    "                #take sequence length excluding insertions \n",
    "                read_sequence_insertion_included = read_sequence_insertion_included.upper()\n",
    "                genomic_alignment_sequence_deletion_mistach_included = genomic_alignment_sequence_deletion_mistach_included.upper()\n",
    "                \n",
    "                genomic_alignment_sequence_deletion_mistach_included_mask = np.array(\n",
    "                [char != '-' for char in genomic_alignment_sequence_deletion_mistach_included])\n",
    "\n",
    "                insertions = read_sequence_insertion_included.count (\"-\")\n",
    "                no_insertion_no_deletion_sequence_length = len(read_sequence_insertion_included)\n",
    "\n",
    "                #make a mod np array with the length of the read length\n",
    "                mod=read.modified_bases_forward\n",
    "                \n",
    "                #make a mod score with its original length \n",
    "                mod_score = np.zeros(len(genomic_alignment_sequence_deletion_mistach_included),)\n",
    "                try:\n",
    "                    if mod_tag == 'A':\n",
    "                        for indices, values in mod[('A', 0, 'a')]:\n",
    "                            mod_score[indices] = values\n",
    "                        mod_score = mod_score[genomic_alignment_sequence_deletion_mistach_included_mask]\n",
    "                        \n",
    "\n",
    "\n",
    "                    elif mod_tag == 'CG':\n",
    "                        for indices, values in mod[('C', 0, 'm')]:\n",
    "                            mod_score[indices] = values\n",
    "                        mod_score = mod_score[genomic_alignment_sequence_deletion_mistach_included_mask]\n",
    "                    \n",
    "                    if read.is_reverse:\n",
    "                            mod_score = mod_score[::-1]\n",
    "\n",
    "\n",
    "                # No mod would return KeyError \n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "                mod_score = np.where(mod_score < filtering_val, 0, mod_score)\n",
    "\n",
    "\n",
    "\n",
    "                # if the regions are longer than the reads \n",
    "                if (region_end_index - region_start_index) > (read_end_position - read_start_position):\n",
    "                    # if the reads are inside the region\n",
    "                    if (region_end_index >= read_end_position) and (region_start_index <= read_start_position): \n",
    "                        mod_start = 0\n",
    "                        mod_end = len(read_sequence_insertion_included)\n",
    "                    \n",
    "                    # if the reads cover the later part of the region\n",
    "                    elif (region_end_index < read_end_position) and (region_start_index > read_start_position): \n",
    "                        mod_start = 0\n",
    "                        mod_end = no_insertion_no_deletion_sequence_length - read_end_position - region_end_index\n",
    "\n",
    "                    # if the reads cover the starting part of the region \n",
    "                    elif (region_end_index > read_end_position) and (region_start_index > read_start_position): \n",
    "                        mod_start = region_start_index - read_start_position \n",
    "                        mod_end = no_insertion_no_deletion_sequence_length\n",
    "\n",
    "                        \n",
    "                \n",
    "                # if the reads are longer than the region selected \n",
    "                elif (region_end_index - region_start_index) <= (read_end_position - read_start_position):\n",
    "                    # scenario 1: when the defined region is inside the read\n",
    "                    if (read_start_position <= region_start_index) and (read_end_position >= region_end_index):\n",
    "                        mod_start = region_start_index - read_start_position \n",
    "                        mod_end = region_end_index - read_start_position\n",
    "\n",
    "                    # scenario 3: when the defined region covers a bit of the end of the read\n",
    "                    elif (read_end_position < region_end_index) and (read_end_position > region_start_index):\n",
    "                        mod_start = region_start_index - read_start_position\n",
    "                        mod_end = no_insertion_no_deletion_sequence_length\n",
    "\n",
    "                    # scenario 2: when the defined region covers a bit of the beginning of the read\n",
    "                    elif (read_start_position > region_start_index) and (read_start_position < region_end_index):\n",
    "                        mod_start = 0\n",
    "                        mod_end = region_end_index - read_start_position \n",
    "\n",
    "                #use the defined starting and ending positons in the region to subset mod numpy\n",
    "                if (region_start_index - read_start_position) > (no_insertion_no_deletion_sequence_length - insertions):\n",
    "                    continue\n",
    "                try:\n",
    "                    trimmed_mod_score = mod_subset_producing_step (mod_score,read_sequence_insertion_included,mod_start,mod_end)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                \n",
    "            \n",
    "                region_base += (mod_end - mod_start)\n",
    "                #removing all the zeros \n",
    "                mod_no_zeros = trimmed_mod_score[trimmed_mod_score != 0]\n",
    "                m_mod_tag = len (mod_no_zeros)\n",
    "                \n",
    "\n",
    "                #Getting the total amount of As in the subsetted region of the sequence \n",
    "                total_mod_tag = read_sequence_insertion_included[mod_start:mod_end].count(mod_tag)\n",
    "            \n",
    "            \n",
    "                #calculate read density\n",
    "                try:\n",
    "                    read_density = m_mod_tag / total_mod_tag\n",
    "                    if read_name in read_CDR_region_distribution:\n",
    "                        read_CDR_region_distribution[read_name].append ([m_mod_tag,total_mod_tag,region_start_index])\n",
    "                    else: \n",
    "                        read_CDR_region_distribution[read_name] = [[m_mod_tag,total_mod_tag,region_start_index]]\n",
    "                    \n",
    "                except ZeroDivisionError:\n",
    "                    pass\n",
    "\n",
    "                \n",
    "\n",
    "                if mod_tag == \"A\":\n",
    "\n",
    "                    read_CDR_location_density = {}\n",
    "                    read_CDR_location_density[region_start_index] = read_density\n",
    "                    if read_name+\"*\"+chromosome in read_region_check: \n",
    "                        read_region_check[read_name+\"*\"+chromosome].append (read_CDR_location_density)\n",
    "                    else: \n",
    "                        read_region_check[read_name+\"*\"+chromosome]= [read_CDR_location_density]\n",
    "\n",
    "                    \n",
    "                    \n",
    "                elif mod_tag == \"CG\":\n",
    "                    read_CDR_location_density = {}\n",
    "                    read_CDR_location_density[region_start_index] = read_density\n",
    "                    if read_name+\"*\"+chromosome in read_region_check:\n",
    "                        read_region_check[read_name+\"*\"+chromosome].append (read_CDR_location_density)\n",
    "                    else:\n",
    "                        read_region_check[read_name+\"*\"+chromosome]= [read_CDR_location_density]\n",
    "\n",
    "\n",
    "\n",
    "    return  read_region_check, read_CDR_region_distribution\n",
    "\n",
    "                                \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamfile = pysam.AlignmentFile(CENPC_AS_bam_file, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CENPC_reads_non_CDR_dict_mC, CENPC_reads_non_CDR_distribution_mC = region_read_mA_density_calculator (trimmed_segmented_chromosome_non_CDR_dict,0,\"CG\",210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENPC_reads_CDR_dict_mC, CENPC_reads_CDR_distribution_mC = region_read_mA_density_calculator (segmented_chromosome_CDR_dict,0,\"CG\",210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/private/groups/migalab/dan/gini_heatmap/CENPC_reads_non_CDR_dict_mC.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPC_reads_non_CDR_dict_mC.items():\n",
    "        writer.writerow([key] + value)\n",
    "with open('/private/groups/migalab/dan/gini_heatmap/CENPC_reads_non_CDR_distribution_dict_mC.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPC_reads_non_CDR_distribution_mC.items():\n",
    "        writer.writerow([key] + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/private/groups/migalab/dan/gini_heatmap/CENPC_reads_CDR_dict_mC.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPC_reads_CDR_dict_mC.items():\n",
    "        writer.writerow([key] + value)\n",
    "with open('/private/groups/migalab/dan/gini_heatmap/CENPC_reads_CDR_distribution_dict_mC.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPC_reads_CDR_distribution_mC.items():\n",
    "        writer.writerow([key] + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENPC_reads_non_CDR_dict_mA, CENPC_reads_non_CDR_distribution_dict_mA = region_read_mA_density_calculator (trimmed_segmented_chromosome_non_CDR_dict,0,\"A\",230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENPC_reads_CDR_dict_mA, CENPC_reads_CDR_distributiondict_mA = region_read_mA_density_calculator (segmented_chromosome_CDR_dict,0,\"A\",230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/private/groups/migalab/dan/gini_heatmap/CENPC_reads_non_CDR_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPC_reads_non_CDR_dict_mA.items():\n",
    "        writer.writerow([key] + value)\n",
    "with open('/private/groups/migalab/dan/gini_heatmap/CENPC_reads_non_CDR_distribution_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPC_reads_non_CDR_distribution_dict_mA.items():\n",
    "        writer.writerow([key] + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/private/groups/migalab/dan/gini_heatmap/CENPC_reads_CDR_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPC_reads_CDR_dict_mA.items():\n",
    "        writer.writerow([key] + value)\n",
    "with open('/private/groups/migalab/dan/gini_heatmap/CENPC_reads_CDR_distribution_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPC_reads_CDR_distributiondict_mA.items():\n",
    "        writer.writerow([key] + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m CENPC_reads_non_CDR_dict_mC, CENPC_reads_non_CDR_distribution_mC \u001b[38;5;241m=\u001b[39m \u001b[43mregion_read_mA_density_calculator\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrimmed_segmented_chromosome_non_CDR_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m210\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 45\u001b[0m, in \u001b[0;36mregion_read_mA_density_calculator\u001b[0;34m(chromosome_coordinates, threshold, mod_tag, filtering_val)\u001b[0m\n\u001b[1;32m     42\u001b[0m genomic_alignment_sequence_deletion_mistach_included \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sequence:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         read_sequence_insertion_included\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m item[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamfile = pysam.AlignmentFile(H3K9me3_AS_bam_file, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "H3K9_reads_non_CDR_dict_mA, H3K9_reads_non_CDR_distribution_mA = region_read_mA_density_calculator (trimmed_segmented_chromosome_non_CDR_dict,0,\"A\",230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/private/groups/migalab/dan/gini_heatmap/H3K9_reads_non_CDR_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in H3K9_reads_non_CDR_dict_mA.items():\n",
    "        writer.writerow([key] + value)\n",
    "with open('/private/groups/migalab/dan/gini_heatmap/H3K9_reads_non_CDR_distribution_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in H3K9_reads_non_CDR_distribution_mA.items():\n",
    "        writer.writerow([key] + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "H3K9_reads_CDR_dict_mA, H3K9_reads_CDR_distribution_mA = region_read_mA_density_calculator (segmented_chromosome_CDR_dict,0,\"A\",230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "H3K9_reads_CDR_dict_mC, H3K9_reads_CDR_distribution_mC = region_read_mA_density_calculator (segmented_chromosome_CDR_dict,0,\"CG\",210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/private/groups/migalab/dan/gini_heatmap/H3K9_reads_CDR_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in H3K9_reads_CDR_dict_mA.items():\n",
    "        writer.writerow([key] + value)\n",
    "with open('/private/groups/migalab/dan/gini_heatmap/H3K9_reads_CDR_distribution_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in H3K9_reads_CDR_distribution_mA.items():\n",
    "        writer.writerow([key] + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamfile = pysam.AlignmentFile(CENPC_AS_bam_file, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENPC_reads_CDR_dict_mC, CENPC_reads_CDR_distribution_dict_mC = region_read_mA_density_calculator (segmented_chromosome_CDR_dict,0,\"CG\",210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENPC_reads_non_CDR_dict_mA, CENPC_reads_non_CDR_distribution_dict_mA = region_read_mA_density_calculator (trimmed_segmented_chromosome_non_CDR_dict,0,\"A\",230)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/private/groups/migalab/dan/CENPC_reads_non_CDR_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPC_reads_non_CDR_dict_mA.items():\n",
    "        writer.writerow([key] + value)\n",
    "\n",
    "with open('/private/groups/migalab/dan/CENPC_reads_non_CDR_distribution_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPC_reads_non_CDR_distribution_dict_mA.items():\n",
    "        writer.writerow([key] + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/private/groups/migalab/dan/CENPC_reads_CDR_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPC_reads_CDR_dict_mA.items():\n",
    "        writer.writerow([key] + value)\n",
    "\n",
    "with open('/private/groups/migalab/dan/CENPC_reads_CDR_distribution_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPC_reads_CDR_distribution_dict_mA.items():\n",
    "        writer.writerow([key] + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamfile = pysam.AlignmentFile(CENPA_AS_bam_file, \"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENPA_reads_CDR_dict_mA, CENPA_reads_CDR_distributiondict_mA = region_read_mA_density_calculator (segmented_chromosome_CDR_dict,0,\"A\",230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/private/groups/migalab/dan/CENPA_reads_CDR_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPA_reads_CDR_dict_mA.items():\n",
    "        writer.writerow([key] + value)\n",
    "\n",
    "with open('/private/groups/migalab/dan/CENPA_reads_CDR_distribution_dict_mA.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in CENPA_reads_CDR_distributiondict_mA.items():\n",
    "        writer.writerow([key] + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "H3K9_reads_non_CDR_dict_mA, H3K9_reads_non_CDR_dict_mA = region_read_mA_density_calculator (trimmed_segmented_chromosome_non_CDR_dict,0,\"A\",230)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'region_read_mA_density_calculator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reads_non_CDR_dict_mA, reads_non_CDR_mA_distribution_dict_mA \u001b[38;5;241m=\u001b[39m \u001b[43mregion_read_mA_density_calculator\u001b[49m (trimmed_segmented_chromosome_non_CDR_dict,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCG\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m210\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Save the dictionary to a CSV file\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/private/groups/migalab/dan/reads_non_CDR_dict_mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csv_file:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'region_read_mA_density_calculator' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the dictionary to a CSV file\n",
    "with open('/private/groups/migalab/dan/reads_non_CDR_dict_mA', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in reads_non_CDR_dict_mA.items():\n",
    "        writer.writerow([key] + value)\n",
    "\n",
    "with open('/private/groups/migalab/dan/reads_non_CDR_mA_distribution_dict_mA', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in reads_non_CDR_mA_distribution_dict_mA.items():\n",
    "        writer.writerow([key] + value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_csv_to_dataframe(cdr_path, non_cdr_path):\n",
    "    def load_dict_from_csv(file_path):\n",
    "        with open(file_path, 'r') as csv_file:\n",
    "            reader = csv.reader(csv_file)\n",
    "            return {rows[0]: [ast.literal_eval(item) for item in rows[1:]] for rows in reader}\n",
    "    \n",
    "    reads_CDR_mC = load_dict_from_csv(cdr_path)\n",
    "    reads_non_CDR_mC = load_dict_from_csv(non_cdr_path)\n",
    "    \n",
    "    return reads_CDR_mC, reads_non_CDR_mC\n",
    "\n",
    "def convert_to_chromosome_dict(reads_dict):\n",
    "    \"\"\"\n",
    "    Convert the input dictionary to a new structure where chromosome names are keys,\n",
    "    and the values are lists of dictionaries containing the read names and their content.\n",
    "\n",
    "    Parameters:\n",
    "        reads_dict (dict): Input dictionary with keys in the format 'read*chromosome'.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with chromosome names as keys and lists of dictionaries as values.\n",
    "    \"\"\"\n",
    "    chromosome_dict = {}\n",
    "\n",
    "    for key, content in reads_dict.items():\n",
    "        # Split the key into read name and chromosome name\n",
    "        read_name, chromosome = key.split('*')\n",
    "\n",
    "        # Initialize the chromosome key if not already present\n",
    "        if chromosome not in chromosome_dict:\n",
    "            chromosome_dict[chromosome] = {}\n",
    "\n",
    "        # Append the read and its content as a dictionary to the chromosome key\n",
    "        chromosome_dict[chromosome][key] = content\n",
    "\n",
    "    return chromosome_dict\n",
    "\n",
    "def parse_and_convert(cdr_path, non_cdr_path):\n",
    "    reads_CDR_mC, reads_non_CDR_mC = parse_csv_to_dataframe(cdr_path, non_cdr_path)\n",
    "    \n",
    "    chromosome_dict_reads_CDR_mC = convert_to_chromosome_dict(reads_CDR_mC)\n",
    "    chromosome_dict_reads_non_CDR_mC = convert_to_chromosome_dict(reads_non_CDR_mC)\n",
    "    \n",
    "    return chromosome_dict_reads_CDR_mC, chromosome_dict_reads_non_CDR_mC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENPA_CDR_dict_mC = '/private/groups/migalab/dan/gini_heatmap/CENPA_reads_CDR_dict_mC.csv'\n",
    "CENPA_non_CDR_dict_mC = '/private/groups/migalab/dan/gini_heatmap/CENPA_reads_non_CDR_dict_mC.csv'\n",
    "CENPA_chromosome_dict_reads_CDR_mC, CENPA_chromosome_dict_reads_non_CDR_mC= parse_and_convert(CENPA_CDR_dict_mC, CENPA_non_CDR_dict_mC)\n",
    "\n",
    "CENPC_CDR_dict_mC = '/private/groups/migalab/dan/gini_heatmap/CENPC_reads_CDR_dict_mC.csv'\n",
    "CENPC_non_CDR_dict_mC = '/private/groups/migalab/dan/gini_heatmap/CENPC_reads_non_CDR_dict_mC.csv'\n",
    "CENPC_chromosome_dict_reads_CDR_mC, CENPC_chromosome_dict_reads_non_CDR_mC= parse_and_convert(CENPC_CDR_dict_mC, CENPC_non_CDR_dict_mC)\n",
    "\n",
    "H3K9_CDR_dict_mC = '/private/groups/migalab/dan/gini_heatmap/H3K9_reads_CDR_dict_mC.csv'\n",
    "H3K9_non_CDR_dict_mC = '/private/groups/migalab/dan/gini_heatmap/H3K9_reads_non_CDR_dict_mC.csv'\n",
    "H3K9_chromosome_dict_reads_CDR_mC, H3K9_chromosome_dict_reads_non_CDR_mC= parse_and_convert(H3K9_CDR_dict_mC, H3K9_non_CDR_dict_mC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_density_by_chromosome(big_dict):\n",
    "    \"\"\"\n",
    "    Aggregates density values for each chromosome from a nested dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        big_dict (dict): A nested dictionary where keys are in the format 'UniqueReadID*ChromosomeName'\n",
    "                         and values are lists of secondary dictionaries with starting positions as keys\n",
    "                         and density values as values.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where each chromosome name is a key, and the values are lists of aggregated density values.\n",
    "    \"\"\"\n",
    "    # Create an empty dictionary to hold the aggregated densities for each chromosome\n",
    "    chromosome_density_dict = {}\n",
    "\n",
    "    # Iterate over the big dictionary\n",
    "    for big_key, secondary_list in big_dict.items():\n",
    "        # Extract the chromosome name from the big key\n",
    "        chrom_name = big_key.split(\"*\")[1]\n",
    "        \n",
    "        # Initialize the chromosome key in the new dictionary if not already present\n",
    "        if chrom_name not in chromosome_density_dict:\n",
    "            chromosome_density_dict[chrom_name] = []\n",
    "        \n",
    "        # Iterate over the list of secondary dictionaries\n",
    "        for small_dict in secondary_list:\n",
    "            # Add all density values to the corresponding chromosome key\n",
    "            for density in small_dict.values():\n",
    "                chromosome_density_dict[chrom_name].append(density)\n",
    "    \n",
    "    return chromosome_density_dict\n",
    "CV_mA_chrom__non_CDR_result = aggregate_density_by_chromosome(reads_non_CDR_mC)\n",
    "CV_mA_chrom_CDR_result = aggregate_density_by_chromosome(reads_CDR_mC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV for non CDR \n",
      "\n",
      "Coefficient of Variation (CV) between chromosomes = 0.0849\n",
      "CV for CDR \n",
      "\n",
      "Coefficient of Variation (CV) between chromosomes = 0.1594\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_cv_between_chromosomes(chromosome_density_dict):\n",
    "    \"\"\"\n",
    "    Calculates the Coefficient of Variation (CV) between chromosomes\n",
    "    based on the average density value for each chromosome.\n",
    "\n",
    "    Parameters:\n",
    "        chromosome_density_dict (dict): A dictionary where each chromosome name is a key, \n",
    "                                        and the values are lists of aggregated density values.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the CV between chromosomes.\n",
    "    \"\"\"\n",
    "    # Calculate the average density for each chromosome\n",
    "    average_densities = []\n",
    "\n",
    "    for chrom, densities in chromosome_density_dict.items():\n",
    "        # Skip empty lists to avoid division by zero\n",
    "        if len(densities) == 0:\n",
    "            print(f\"{chrom}: No data available.\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate the average density for the chromosome\n",
    "        avg_density = np.mean(densities)\n",
    "        average_densities.append(avg_density)\n",
    "\n",
    "    # Convert to a numpy array for easy calculation\n",
    "    average_densities_array = np.array(average_densities)\n",
    "\n",
    "    # Calculate mean and standard deviation of the average densities\n",
    "    mean_avg_density = np.mean(average_densities_array)\n",
    "    std_dev_avg_density = np.std(average_densities_array)\n",
    "\n",
    "    # Calculate Coefficient of Variation (CV = SD / Mean)\n",
    "    if mean_avg_density != 0:\n",
    "        cv = std_dev_avg_density / mean_avg_density\n",
    "        print(f\"\\nCoefficient of Variation (CV) between chromosomes = {cv:.4f}\")\n",
    "\n",
    "\n",
    "print (\"CV for non CDR \")\n",
    "calculate_cv_between_chromosomes(CV_mA_chrom__non_CDR_result)\n",
    "\n",
    "print (\"CV for CDR \")\n",
    "calculate_cv_between_chromosomes(CV_mA_chrom_CDR_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def extract_and_find_optimal_threshold(reads_non_CDR_dict_mA, reads_spanning_dict_mA):\n",
    "    \"\"\"\n",
    "    Combined function to extract densities, label them, and find the optimal threshold based on Gini impurity.\n",
    "\n",
    "    Parameters:\n",
    "        reads_non_CDR_dict_mA (dict): Dictionary for the non-CDR group.\n",
    "        reads_spanning_dict_mA (dict): Dictionary for the spanning group.\n",
    "\n",
    "    Returns:\n",
    "        best_threshold (float): The threshold with the lowest Gini impurity.\n",
    "        best_gini (float): The Gini impurity at the best threshold.\n",
    "        purity_info (dict): Dictionary containing purity percentages of left and right labels.\n",
    "        y_pred (list): Predicted labels based on the best threshold.\n",
    "    \"\"\"\n",
    "    def extract_densities(data_dict, class_label):\n",
    "        extracted_data = []\n",
    "        for value_list in data_dict.values():\n",
    "            for density_dict in value_list:\n",
    "                for _, density in density_dict.items():\n",
    "                    extracted_data.append((density, class_label))\n",
    "        return extracted_data\n",
    "\n",
    "    def calculate_gini_impurity(subset):\n",
    "        total_samples = len(subset)\n",
    "        if total_samples == 0:\n",
    "            return 0\n",
    "        class_counts = np.bincount(subset, minlength=2)\n",
    "        probabilities = class_counts / total_samples\n",
    "        return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "    # Extract training data\n",
    "    training_data_class_1 = extract_densities(reads_non_CDR_dict_mA, class_label=1)\n",
    "    training_data_class_0 = extract_densities(reads_spanning_dict_mA, class_label=0)\n",
    "    training_data = training_data_class_1 + training_data_class_0\n",
    "\n",
    "    # Sort data by density\n",
    "    training_data = sorted(training_data, key=lambda x: x[0])\n",
    "    densities = [d[0] for d in training_data]\n",
    "    labels = [d[1] for d in training_data]\n",
    "\n",
    "    midpoints = [(densities[i] + densities[i + 1]) / 2 for i in range(len(densities) - 1)]\n",
    "\n",
    "    best_threshold = None\n",
    "    best_gini = float('inf')\n",
    "    purity_info = {}\n",
    "\n",
    "    for threshold in midpoints:\n",
    "        left_labels = [label for density, label in zip(densities, labels) if density <= threshold]\n",
    "        right_labels = [label for density, label in zip(densities, labels) if density > threshold]\n",
    "\n",
    "        gini_left = calculate_gini_impurity(left_labels)\n",
    "        gini_right = calculate_gini_impurity(right_labels)\n",
    "\n",
    "        total_samples = len(labels)\n",
    "        weighted_gini = (len(left_labels) / total_samples) * gini_left + (len(right_labels) / total_samples) * gini_right\n",
    "\n",
    "        if weighted_gini < best_gini:\n",
    "            best_gini = weighted_gini\n",
    "            best_threshold = threshold\n",
    "\n",
    "            left_class_counts = np.bincount(left_labels, minlength=2)\n",
    "            right_class_counts = np.bincount(right_labels, minlength=2)\n",
    "\n",
    "            left_purity = (left_class_counts / len(left_labels)) * 100 if len(left_labels) > 0 else [0, 0]\n",
    "            right_purity = (right_class_counts / len(right_labels)) * 100 if len(right_labels) > 0 else [0, 0]\n",
    "\n",
    "            purity_info = {\n",
    "                \"non_CDR group purity\": left_purity.tolist(),\n",
    "                \"CDR group purity\": right_purity.tolist()\n",
    "            }\n",
    "\n",
    "    y_pred = [0 if density > best_threshold else 1 for density in densities]\n",
    "\n",
    "    return best_threshold, best_gini, purity_info, y_pred\n",
    "\n",
    "\n",
    "# Run the combined function\n",
    "\n",
    "CENPA_mC_threshold_chrom ={} \n",
    "for chrom in CENPA_chromosome_dict_reads_non_CDR_mC: \n",
    "    best_threshold_chrom, best_gini_chrom, purity_info_chrom, y_pred_chrom = extract_and_find_optimal_threshold(CENPA_chromosome_dict_reads_non_CDR_mC[chrom], CENPA_chromosome_dict_reads_CDR_mC[chrom] )\n",
    "    CENPA_mC_threshold_chrom[chrom] = best_threshold_chrom\n",
    "\n",
    "\n",
    "CENPC_mC_threshold_chrom ={} \n",
    "for chrom in CENPC_chromosome_dict_reads_non_CDR_mC: \n",
    "    best_threshold_chrom, best_gini_chrom, purity_info_chrom, y_pred_chrom = extract_and_find_optimal_threshold(CENPC_chromosome_dict_reads_non_CDR_mC[chrom], CENPC_chromosome_dict_reads_CDR_mC[chrom] )\n",
    "    CENPC_mC_threshold_chrom[chrom] = best_threshold_chrom\n",
    "\n",
    "H3K9_mC_threshold_chrom ={} \n",
    "for chrom in H3K9_chromosome_dict_reads_non_CDR_mC: \n",
    "    best_threshold_chrom, best_gini_chrom, purity_info_chrom, y_pred_chrom = extract_and_find_optimal_threshold(H3K9_chromosome_dict_reads_non_CDR_mC[chrom], H3K9_chromosome_dict_reads_CDR_mC[chrom] )\n",
    "    H3K9_mC_threshold_chrom[chrom] = best_threshold_chrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENPA_CDR_dict_mA_path = '/private/groups/migalab/dan/gini_heatmap/CENPA_reads_CDR_dict_mA.csv'\n",
    "CENPA_non_CDR_dict_mA_path = '/private/groups/migalab/dan/gini_heatmap/CENPA_reads_non_CDR_dict_mA.csv'\n",
    "\n",
    "CENPA_reads_CDR_mA, CENPA_reads_non_CDR_mA = parse_csv_to_dataframe(CENPA_CDR_dict_mA_path, CENPA_non_CDR_dict_mA_path)\n",
    "\n",
    "best_threshold_chrom, best_gini_chrom, purity_info_chrom, y_pred_chrom = extract_and_find_optimal_threshold(CENPA_reads_non_CDR_mA, CENPA_reads_CDR_mA )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010980930464155464 0.2581402733764441 {'non_CDR group purity': [14.017638882231703, 85.9823611177683], 'CDR group purity': [83.54239009755983, 16.457609902440176]}\n"
     ]
    }
   ],
   "source": [
    "print (best_threshold_chrom, best_gini_chrom, purity_info_chrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013633102908569193 0.26154258657199586 {'non_CDR group purity': [11.804161343310824, 88.19583865668918], 'CDR group purity': [80.85447592417452, 19.145524075825488]}\n"
     ]
    }
   ],
   "source": [
    "CENPC_CDR_dict_mA_path = '/private/groups/migalab/dan/gini_heatmap/CENPC_reads_CDR_dict_mA.csv'\n",
    "CENPC_non_CDR_dict_mA_path = '/private/groups/migalab/dan/gini_heatmap/CENPC_reads_non_CDR_dict_mA.csv'\n",
    "\n",
    "CENPC_reads_CDR_mA, CENPC_reads_non_CDR_mA = parse_csv_to_dataframe(CENPC_CDR_dict_mA_path, CENPC_non_CDR_dict_mA_path)\n",
    "\n",
    "best_threshold_chrom, best_gini_chrom, purity_info_chrom, y_pred_chrom = extract_and_find_optimal_threshold(CENPC_reads_non_CDR_mA, CENPC_reads_CDR_mA )\n",
    "print (best_threshold_chrom, best_gini_chrom, purity_info_chrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014652014652014652 0.3377920594569553 {'non_CDR group purity': [84.22331940751994, 15.77668059248006], 'CDR group purity': [25.37729127534167, 74.62270872465834]}\n"
     ]
    }
   ],
   "source": [
    "H3K9_CDR_dict_mA_path = '/private/groups/migalab/dan/gini_heatmap/H3K9_reads_CDR_dict_mA.csv'\n",
    "H3K9_non_CDR_dict_mA_path = '/private/groups/migalab/dan/gini_heatmap/H3K9_reads_non_CDR_dict_mA.csv'\n",
    "\n",
    "H3K9_reads_CDR_mA, H3K9_reads_non_CDR_mA = parse_csv_to_dataframe(H3K9_CDR_dict_mA_path, H3K9_non_CDR_dict_mA_path)\n",
    "\n",
    "best_threshold_chrom, best_gini_chrom, purity_info_chrom, y_pred_chrom = extract_and_find_optimal_threshold(H3K9_reads_non_CDR_mA, H3K9_reads_CDR_mA )\n",
    "print (best_threshold_chrom, best_gini_chrom, purity_info_chrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[41215     0]\n",
      " [ 1118 41726]]\n"
     ]
    }
   ],
   "source": [
    "# Extract the true labels\n",
    "y_true = [d[1] for d in combined_training_data]\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81     41215\n",
      "           1       0.79      0.90      0.84     42844\n",
      "\n",
      "    accuracy                           0.83     84059\n",
      "   macro avg       0.83      0.83      0.83     84059\n",
      "weighted avg       0.83      0.83      0.83     84059\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30773 10442]\n",
      " [ 4105 38739]]\n",
      "Cutoff Threshold: 0.016968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def prepare_data_for_logistic_regression(data):\n",
    "    \"\"\"\n",
    "    Prepare the data for logistic regression by separating densities and labels.\n",
    "\n",
    "    Parameters:\n",
    "        data (list of tuples): Each tuple contains (density, label).\n",
    "\n",
    "    Returns:\n",
    "        X (ndarray): Feature array (densities).\n",
    "        y (ndarray): Label array.\n",
    "    \"\"\"\n",
    "    X = np.array([d[0] for d in data]).reshape(-1, 1)\n",
    "    y = np.array([d[1] for d in data])\n",
    "    return X, y\n",
    "\n",
    "def train_logistic_regression(X, y):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model on the given data.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): Feature array (densities).\n",
    "        y (ndarray): Label array.\n",
    "\n",
    "    Returns:\n",
    "        model: Trained logistic regression model.\n",
    "    \"\"\"\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def get_cutoff_threshold(model):\n",
    "    \"\"\"\n",
    "    Calculate the cutoff threshold for logistic regression.\n",
    "\n",
    "    Parameters:\n",
    "        model: Trained logistic regression model.\n",
    "\n",
    "    Returns:\n",
    "        threshold (float): The density threshold that separates CDR from non-CDR.\n",
    "    \"\"\"\n",
    "    intercept = model.intercept_[0]\n",
    "    coefficient = model.coef_[0][0]\n",
    "    threshold = -intercept / coefficient\n",
    "    return threshold\n",
    "\n",
    "def evaluate_logistic_regression(model, X, y):\n",
    "    \"\"\"\n",
    "    Evaluate the logistic regression model and display classification report, confusion matrix, and cutoff threshold.\n",
    "\n",
    "    Parameters:\n",
    "        model: Trained logistic regression model.\n",
    "        X (ndarray): Feature array (densities).\n",
    "        y (ndarray): Label array.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    report = classification_report(y, y_pred)\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "    cutoff_threshold = get_cutoff_threshold(model)\n",
    "\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    print(f\"Cutoff Threshold: {cutoff_threshold:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Prepare the data\n",
    "X, y = prepare_data_for_logistic_regression(combined_training_data)\n",
    "\n",
    "# Train the logistic regression model\n",
    "logistic_model = train_logistic_regression(X, y)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_logistic_regression(logistic_model, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
